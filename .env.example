# ClariGen Environment Configuration
# Copy this file to .env and update with your settings

# =============================================================================
# Model Server Configuration
# =============================================================================

# Small Model (8B) - Used for fast binary ambiguity detection
SMALL_MODEL_URL=http://localhost:8368/v1
SMALL_MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct

# Large Model (70B) - Used for clarification generation and reasoning
LARGE_MODEL_URL=http://localhost:8369/v1
LARGE_MODEL_NAME=nvidia/Llama-3.3-70B-Instruct-FP8

# vLLM API Key (used for authentication with model servers)
VLLM_API_KEY=token-abc123

# =============================================================================
# Application Configuration
# =============================================================================

# API URL (used by frontend to connect to backend)
# For local development: http://localhost:8370/v1
# For Docker: http://api:8370/v1
API_URL=http://localhost:8370/v1

# =============================================================================
# Pipeline Configuration
# =============================================================================

# Maximum number of clarification attempts before giving up
MAX_CLARIFICATION_ATTEMPTS=3

# Clarification strategy: "at_standard", "at_cot", or "vanilla"
# - at_standard: Standard ambiguity type-based prompting
# - at_cot: Chain-of-thought reasoning
# - vanilla: Simple prompting without ambiguity types
CLARIFICATION_STRATEGY=at_standard

# =============================================================================
# Logging Configuration
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (optional, leave empty to log to console only)
# LOG_FILE=/path/to/logfile.log
LOG_FILE=

# =============================================================================
# Testing Configuration
# =============================================================================

# Skip integration tests (set to "true" to skip)
SKIP_INTEGRATION_TESTS=false

# =============================================================================
# Docker-Specific Configuration
# =============================================================================
# These are used when running with docker-compose
# Uncomment and modify if deploying with Docker

# SMALL_MODEL_URL=http://130.113.68.24:8368/v1
# LARGE_MODEL_URL=http://130.113.68.24:8369/v1
# API_URL=http://api:8370/v1
